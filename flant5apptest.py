
import streamlit as st
import mlflow
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from huggingface_hub import hf_hub_download

# === STREAMLIT CONFIG ===
st.set_page_config(page_title="Cincinnati Crime Chatbot", page_icon="ðŸš“")
st.title("ðŸš” Cincinnati Crime Chatbot")
st.markdown("Ask about recent police activity in your neighborhood.")

mlflow.set_tracking_uri("http://3.145.180.106:5000")
mlflow.set_experiment("Cincinnati Crime Chatbot")

# === MODEL ===
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
    model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
    return tokenizer, model

tokenizer, model = load_model()

# === SIMPLE UI ===
question = st.text_input("Ask your question:")
if question:
    input_ids = tokenizer.encode(question, return_tensors="pt")
    output = model.generate(input_ids, max_length=128)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    st.write("Response:", response)
