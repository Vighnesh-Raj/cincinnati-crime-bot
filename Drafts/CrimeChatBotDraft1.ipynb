{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e4edcf-922f-4748-aacc-88fffb01e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://3.145.180.106:5000\")\n",
    "mlflow.set_experiment(\"Cincinnati Crime Chatbot\")\n",
    "\n",
    "import transformers\n",
    "import huggingface_hub\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0dc4330-d5e2-4278-85df-f99e322066ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and model...\n",
      "Columns in dataset: ['address_x', 'agency', 'create_time_incident', 'disposition_text', 'event_number', 'incident_type_id', 'incident_type_desc', 'priority', 'priority_color', 'arrival_time_primary_unit', 'closed_time_incident', 'dispatch_time_primary_unit', 'beat', 'district', 'cpd_neighborhood', 'community_council_neighborhood', 'latitude_x', 'longitude_x', 'sna_neighborhood']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chatbot is ready! Ask your question below:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c918d921cba46d58e18b212fa748895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Question:', layout=Layout(width='100%'), placeholder='Ask a question about crime i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5447c007fd044a078174e8759195679a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import time\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "\n",
    "# --- Load Cincinnati crime data from Hugging Face ---\n",
    "def load_crime_data():\n",
    "    csv_path = hf_hub_download(\n",
    "        repo_id=\"mlsystemsg1/cincinnati-crime-data\",\n",
    "        repo_type=\"dataset\",\n",
    "        filename=\"calls_for_service_latest.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "    # Normalize column names (lowercase)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# --- Filter relevant rows based on question ---\n",
    "def get_relevant_rows(question, df, num_rows=10):\n",
    "    q = question.lower()\n",
    "    filtered = df.copy()\n",
    "\n",
    "    # Filter by neighborhood\n",
    "    if 'sna_neighborhood' in df.columns:\n",
    "        for neighborhood in df['sna_neighborhood'].dropna().unique():\n",
    "            if neighborhood.lower() in q:\n",
    "                filtered = filtered[filtered['sna_neighborhood'].str.contains(neighborhood, case=False, na=False)]\n",
    "                break\n",
    "\n",
    "    # Filter by offense type\n",
    "    if 'incident_type_desc' in df.columns:\n",
    "        for offense in df['incident_type_desc'].dropna().unique():\n",
    "            if offense.lower() in q:\n",
    "                filtered = filtered[filtered['incident_type_desc'].str.contains(offense, case=False, na=False)]\n",
    "                break\n",
    "\n",
    "    # Sort by date if user asks about recent crimes\n",
    "    if 'create_time_incident' in df.columns and any(word in q for word in [\"last\", \"latest\", \"recent\"]):\n",
    "        filtered = filtered.sort_values(by='create_time_incident', ascending=False)\n",
    "\n",
    "    return filtered.head(min(num_rows, len(filtered)))\n",
    "\n",
    "\n",
    "# --- Summarize or extract information ---\n",
    "def generate_summary(question, filtered_df):\n",
    "    q = question.lower()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return \"No matching records found.\"\n",
    "\n",
    "    if any(word in q for word in [\"how many\", \"number of\", \"count\"]):\n",
    "        return f\"{len(filtered_df)} incidents matched your query.\"\n",
    "\n",
    "    if \"most common\" in q and 'incident_type_desc' in filtered_df.columns:\n",
    "        most_common = filtered_df['incident_type_desc'].value_counts().idxmax()\n",
    "        count = filtered_df['incident_type_desc'].value_counts().max()\n",
    "        return f\"The most common crime is {most_common} with {count} incidents.\"\n",
    "\n",
    "\n",
    "    # Fallback: return example incidents\n",
    "    examples = []\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        try:\n",
    "            date = row.get('create_time_incident', 'N/A')\n",
    "            offense = row.get('incident_type_desc', 'N/A')\n",
    "            neighborhood = row.get('sna_neighborhood', 'N/A')\n",
    "            incident = row.get('event_number', 'N/A')\n",
    "            examples.append(f\"On {date}, a {offense} occurred in {neighborhood} (Incident #{incident}).\")\n",
    "        except:\n",
    "            continue\n",
    "    return \"\\n\".join(examples[:10])\n",
    "\n",
    "# --- Use the LLM to generate an answer and log with MLflow ---\n",
    "def answer_with_llm(question, data_rows, model, model_name=\"google/flan-t5-base\", prompt_version=\"v3\"):\n",
    "    if data_rows.empty:\n",
    "        return \"Sorry, I couldn't find any data matching that question.\"\n",
    "\n",
    "    context = generate_summary(question, data_rows)\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant analyzing Cincinnati crime data.\n",
    "\n",
    "Here are some relevant data points:\n",
    "{context}\n",
    "\n",
    "Now answer this question based on the above:\n",
    "{question}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    start_time = time.time()\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"max_new_tokens\", 150)\n",
    "        mlflow.log_param(\"num_rows_context\", len(data_rows))\n",
    "        mlflow.log_param(\"prompt_version\", prompt_version)\n",
    "        mlflow.log_param(\"question\", question)\n",
    "        mlflow.log_text(prompt, \"prompt.txt\")\n",
    "\n",
    "        result = model(prompt, max_new_tokens=150)[0]['generated_text']\n",
    "        answer = result.strip()\n",
    "        latency = time.time() - start_time\n",
    "\n",
    "        mlflow.log_text(answer, \"answer.txt\")\n",
    "        mlflow.log_metric(\"response_length\", len(answer))\n",
    "        mlflow.log_metric(\"latency_sec\", latency)\n",
    "\n",
    "        return answer\n",
    "\n",
    "# --- Chatbot loop ---\n",
    "def run_single_chatbot_turn(df, model, question):\n",
    "    if question.lower() in ['exit', 'quit']:\n",
    "        return \"Goodbye!\"\n",
    "\n",
    "    sample_rows = get_relevant_rows(question, df)\n",
    "    answer = answer_with_llm(question, sample_rows, model)\n",
    "    return answer\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def ask_question_with_widget(df, model):\n",
    "    input_box = widgets.Text(\n",
    "        placeholder='Ask a question about crime in Cincinnati...',\n",
    "        description='Question:',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_submit(change):\n",
    "        output.clear_output()\n",
    "        question = change['new']\n",
    "        answer = run_single_chatbot_turn(df, model, question)\n",
    "        with output:\n",
    "            print(\"Bot:\", answer)\n",
    "\n",
    "    input_box.observe(on_submit, names='value')\n",
    "    display(input_box, output)\n",
    "\n",
    "\n",
    "# --- Load data and model ---\n",
    "print(\"Loading dataset and model...\")\n",
    "df = load_crime_data()\n",
    "print(\"Columns in dataset:\", df.columns.tolist())  # helpful for debugging\n",
    "llm_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# --- Launch chatbot widget ---\n",
    "print(\"\\n Chatbot is ready! Ask your question below:\")\n",
    "ask_question_with_widget(df, llm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f66dc17-9b01-48e6-8f71-a58a8bc6d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking to: http://3.145.180.106:5000\n",
      "Experiment ID: 599682738248006782\n",
      "Artifact Location: mlflow-artifacts:/599682738248006782\n"
     ]
    }
   ],
   "source": [
    "print(\"Tracking to:\", mlflow.get_tracking_uri())\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(\"Cincinnati Crime Chatbot\")\n",
    "print(\"Experiment ID:\", exp.experiment_id)\n",
    "print(\"Artifact Location:\", exp.artifact_location)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
